{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optical-integration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:39.393330Z",
     "start_time": "2021-03-24T07:58:39.378123Z"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becoming-password",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:39.908129Z",
     "start_time": "2021-03-24T07:58:39.892628Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polished-significance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:40.687411Z",
     "start_time": "2021-03-24T07:58:40.677958Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unnecessary-budapest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:42.400081Z",
     "start_time": "2021-03-24T07:58:41.175439Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import regex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import editdistance\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, BatchSampler, SequentialSampler, RandomSampler\n",
    "\n",
    "from vocabulary import Vocab\n",
    "\n",
    "from src.audio_utils import open_audio\n",
    "from src.audio_utils import make_transform, get_default_audio_transforms\n",
    "from src.audio_utils import AudioTransformsChain, AudioTransformsExclusive\n",
    "from src.audio_utils import SpectrogramTransform, compute_log_mel_spectrogram\n",
    "\n",
    "from src.datasets import AudioDataset\n",
    "from src.datasets import AudioDatasetSampler, collate_fn\n",
    "\n",
    "from src.datasets import manifest_train_test_split\n",
    "from src.datasets import convert_libri_manifest_to_common_voice\n",
    "from src.datasets import convert_open_stt_manifest_to_common_voice\n",
    "\n",
    "from src.deepspeech import Model\n",
    "\n",
    "from src.decoding import calc_wer, calc_wer_for_batch\n",
    "from src.decoding import decode, greedy_decoder, beam_search_decode, fast_beam_search_decode\n",
    "\n",
    "from src.optimization import get_prediction, get_model_results\n",
    "from src.optimization import get_prediction, get_model_results, validate, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arranged-corps",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:42.507211Z",
     "start_time": "2021-03-24T07:58:42.402245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: torch.float32, device: cuda:0, cuda_device_id 1\n"
     ]
    }
   ],
   "source": [
    "# Set proper device for computations,\n",
    "dtype, device, cuda_device_id = torch.float32, None, 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{0}'.format(str(cuda_device_id) if cuda_device_id is not None else '')\n",
    "if cuda_device_id is not None and torch.cuda.is_available():\n",
    "    device = 'cuda:{0:d}'.format(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f'dtype: {dtype}, device: {device}, cuda_device_id {cuda_device_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-argument",
   "metadata": {},
   "source": [
    "# Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italian-bouquet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:43.868812Z",
     "start_time": "2021-03-24T07:58:43.848263Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_tokens(vocab):\n",
    "    ### write your code here ###\n",
    "    num_tokens = len(vocab.tokens2indices())\n",
    "    return num_tokens\n",
    "\n",
    "def get_blank_index(vocab):\n",
    "    ### write your code here ###\n",
    "    blank_index = vocab['<blank>']\n",
    "    return blank_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hairy-rochester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:44.090010Z",
     "start_time": "2021-03-24T07:58:44.068153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `unk_token` '<unk>' wasn't found in the tokens. Adding the `unk_token` to the end of the Vocab.\n"
     ]
    }
   ],
   "source": [
    "alphabet = [\n",
    "    'а', 'б', 'в', 'г', 'д', 'е', 'ё', 'ж', 'з', 'и', 'й', 'к',\n",
    "    'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц',\n",
    "    'ч', 'ш', 'щ', 'ь', 'ы', 'ъ', 'э', 'ю', 'я', ' ', '<blank>'\n",
    "]\n",
    "\n",
    "vocab = Vocab(alphabet)\n",
    "\n",
    "num_tokens = get_num_tokens(vocab) \n",
    "blank_index = get_blank_index(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-subscription",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:16:50.445235Z",
     "start_time": "2021-03-23T14:16:50.427831Z"
    }
   },
   "source": [
    "# Choose Audio Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "honest-plastic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:45.296195Z",
     "start_time": "2021-03-24T07:58:45.276706Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_transforms = get_default_audio_transforms()\n",
    "# audio_transforms = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surrounded-amazon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:46.788087Z",
     "start_time": "2021-03-24T07:58:46.769060Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-species",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-portsmouth",
   "metadata": {},
   "source": [
    "## Load Common Voice dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "introductory-corps",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:49.893213Z",
     "start_time": "2021-03-24T07:58:49.666969Z"
    }
   },
   "outputs": [],
   "source": [
    "common_voice_val_manifest_path = '/home/e.chuykova/data/val.txt'\n",
    "common_voice_test_manifest_path = '/home/e.chuykova/data/test.txt'\n",
    "common_voice_train_manifest_path = '/home/e.chuykova/data/train.txt'\n",
    "\n",
    "common_voice_val_dataset = AudioDataset(\n",
    "    common_voice_val_manifest_path, vocab, sample_rate=sample_rate,\n",
    ")\n",
    "common_voice_test_dataset = AudioDataset(\n",
    "    common_voice_test_manifest_path, vocab, sample_rate=sample_rate,\n",
    ")\n",
    "common_voice_train_dataset = AudioDataset(\n",
    "    common_voice_train_manifest_path, vocab, sample_rate=sample_rate,\n",
    "    audio_transforms=audio_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-advertising",
   "metadata": {},
   "source": [
    "## Load LibriSpeech dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "knowing-attention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:52.302478Z",
     "start_time": "2021-03-24T07:58:51.194212Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/dev/manifest.json'\n",
    "ls_test_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/test/manifest.json'\n",
    "ls_train_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/train/manifest.json'\n",
    "\n",
    "ls_dev_manifest_path = convert_libri_manifest_to_common_voice(ls_dev_manifest_path)\n",
    "ls_test_manifest_path = convert_libri_manifest_to_common_voice(ls_test_manifest_path)\n",
    "ls_train_manifest_path = convert_libri_manifest_to_common_voice(ls_train_manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "experienced-worry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:52.564312Z",
     "start_time": "2021-03-24T07:58:52.304572Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_dataset = AudioDataset(\n",
    "    ls_dev_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    ")\n",
    "ls_test_dataset = AudioDataset(\n",
    "    ls_test_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    ")\n",
    "ls_train_dataset = AudioDataset(\n",
    "    ls_train_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-group",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T11:00:14.720362Z",
     "start_time": "2021-03-22T11:00:14.703290Z"
    }
   },
   "source": [
    "## Load Open STT (radio_2) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "genetic-deputy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:53.928529Z",
     "start_time": "2021-03-24T07:58:53.909095Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.csv'\n",
    "\n",
    "# open_stt_manifest_path = convert_open_stt_manifest_to_common_voice(open_stt_manifest_path)\n",
    "# open_stt_test_manifest_path, open_stt_train_manifest_path = manifest_train_test_split(\n",
    "#     open_stt_manifest_path, ratio=0.005, seed=42\n",
    "# )\n",
    "open_stt_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.common_voice.csv'\n",
    "open_stt_test_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.common_voice_test.csv'\n",
    "open_stt_train_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.common_voice_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "enabling-therapy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:57.887971Z",
     "start_time": "2021-03-24T07:58:54.755735Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_test_dataset = AudioDataset(\n",
    "    open_stt_test_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    ")\n",
    "open_stt_train_dataset = AudioDataset(\n",
    "    open_stt_train_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-briefing",
   "metadata": {},
   "source": [
    "## Load Open STT (audiobook_2) dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elegant-essex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:58:58.119640Z",
     "start_time": "2021-03-24T07:58:58.100252Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobook_2_manifest_path = '/data/mnakhodnov/voice_data/private_buriy_audiobooks_2/private_buriy_audiobooks_2.csv'\n",
    "# audiobook_2_manifest_path = convert_open_stt_manifest_to_common_voice(audiobook_2_manifest_path)\n",
    "# audiobook_2_test_manifest_path, audiobook_2_train_manifest_path = manifest_train_test_split(\n",
    "#     audiobook_2_manifest_path, ratio=0.005, seed=42\n",
    "# )\n",
    "audiobook_2_manifest_path = '/data/mnakhodnov/voice_data/private_buriy_audiobooks_2/private_buriy_audiobooks_2.common_voice.csv'\n",
    "audiobook_2_test_manifest_path = '/data/mnakhodnov/voice_data/private_buriy_audiobooks_2/private_buriy_audiobooks_2.common_voice_test.csv'\n",
    "audiobook_2_train_manifest_path = '/data/mnakhodnov/voice_data/private_buriy_audiobooks_2/private_buriy_audiobooks_2.common_voice_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "addressed-maldives",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:03.955881Z",
     "start_time": "2021-03-24T07:58:58.621211Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobook_2_test_dataset = AudioDataset(\n",
    "    audiobook_2_test_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    ")\n",
    "audiobook_2_train_dataset = AudioDataset(\n",
    "    audiobook_2_train_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-helmet",
   "metadata": {},
   "source": [
    "## Combine all datasets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "atmospheric-controversy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:07.547474Z",
     "start_time": "2021-03-24T07:59:03.958066Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_dataset = AudioDataset(\n",
    "    dataset_path=[common_voice_train_manifest_path, ls_train_manifest_path, open_stt_train_manifest_path], \n",
    "    min_duration=[None, None, 2.0], max_duration=[None, 10.0, 10.0],\n",
    "    vocab=vocab, sample_rate=sample_rate,\n",
    "    audio_transforms=audio_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-decade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:15.279798Z",
     "start_time": "2021-03-23T14:19:15.262876Z"
    }
   },
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cutting-seminar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:08.163401Z",
     "start_time": "2021-03-24T07:59:08.143757Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-turning",
   "metadata": {},
   "source": [
    "## Common Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "advanced-billion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:10.061605Z",
     "start_time": "2021-03-24T07:59:10.031045Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "common_voice_val_dataloader = DataLoader(\n",
    "    common_voice_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "# YOUR CODE\n",
    "common_voice_test_dataloader = DataLoader(\n",
    "    common_voice_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "# YOUR CODE\n",
    "common_voice_train_dataloader = DataLoader(\n",
    "    common_voice_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(common_voice_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-brooks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:15.371150Z",
     "start_time": "2021-03-23T14:19:15.356303Z"
    }
   },
   "source": [
    "## Libri Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "current-greek",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:10.472977Z",
     "start_time": "2021-03-24T07:59:10.442836Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_dataloader = DataLoader(\n",
    "    ls_dev_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "ls_test_dataloader = DataLoader(\n",
    "    ls_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "ls_train_dataloader = DataLoader(\n",
    "    ls_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(ls_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-valentine",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:45.209964Z",
     "start_time": "2021-03-23T14:19:45.192687Z"
    }
   },
   "source": [
    "## OpenSTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "elementary-miracle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:11.093934Z",
     "start_time": "2021-03-24T07:59:11.000832Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_test_dataloader = DataLoader(\n",
    "    open_stt_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "open_stt_train_dataloader = DataLoader(\n",
    "    open_stt_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(open_stt_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-entry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:04:47.713051Z",
     "start_time": "2021-03-23T15:04:47.695886Z"
    }
   },
   "source": [
    "## Combined Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hourly-currency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:11.922654Z",
     "start_time": "2021-03-24T07:59:11.798181Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_dataloader = DataLoader(\n",
    "    combined_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(combined_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-gambling",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-briefs",
   "metadata": {},
   "source": [
    "## Choose LM for beam search decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ethical-version",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:13.065066Z",
     "start_time": "2021-03-24T07:59:13.045127Z"
    }
   },
   "outputs": [],
   "source": [
    "kenlm_bin_path = '/home/mnakhodnov/kenlm/build/bin'\n",
    "\n",
    "# This models are sorted wr to their size and speed \n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.1'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.2'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.3'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.4'\n",
    "kenlm_data_path = '/data/mnakhodnov/language_data/common_voice/train.txt'\n",
    "kenlm_arpa_path, kenlm_binary_path = kenlm_data_path + '.arpa', kenlm_data_path + '.binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "young-numbers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:13.270031Z",
     "start_time": "2021-03-24T07:59:13.250443Z"
    }
   },
   "outputs": [],
   "source": [
    "fast_beam_kwargs = {\n",
    "    'beam_size': 10, 'cutoff_top_n': 5, 'cutoff_prob': 1.0, \n",
    "    'ext_scoring_func': kenlm_binary_path, 'alpha': 1.0, 'beta': 0.3, 'num_processes': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "recreational-mortality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:13.422622Z",
     "start_time": "2021-03-24T07:59:13.403110Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_from_ckpt(model, ckpt_path):\n",
    "    checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "funded-burton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:13.677062Z",
     "start_time": "2021-03-24T07:59:13.656832Z"
    }
   },
   "outputs": [],
   "source": [
    "num_tokens = len(vocab.tokens2indices()) - 1\n",
    "num_mel_bins = 64\n",
    "hidden_size= 512\n",
    "num_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "straight-updating",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:40.691552Z",
     "start_time": "2021-03-24T07:59:34.682022Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 7\n",
    "model_dir = 'models/7_recovered'\n",
    "log_every_n_batch = 10\n",
    "\n",
    "model = Model(\n",
    "    num_mel_bins=num_mel_bins,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    num_tokens=num_tokens\n",
    ")\n",
    "# load_from_ckpt(model, '/home/e.chuykova/data/ckpt.pt')\n",
    "# load_from_ckpt(model, '/home/mnakhodnov/sirius-stt/models/6/epoch_5.pt')\n",
    "load_from_ckpt(model, '/home/mnakhodnov/sirius-stt/models/7/epoch_0.pt')\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "graduate-findings",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:42.497658Z",
     "start_time": "2021-03-24T07:59:42.477015Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 2e-4\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CTCLoss(blank=blank_index, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "extreme-paradise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:43.611337Z",
     "start_time": "2021-03-24T07:59:43.592441Z"
    }
   },
   "outputs": [],
   "source": [
    "# ls_train_dataloader.sampler.epoch = 0\n",
    "# open_stt_train_dataloader.sampler.epoch = 0\n",
    "# common_voice_train_dataloader.sampler.epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "specified-munich",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T07:59:45.314278Z",
     "start_time": "2021-03-24T07:59:45.294625Z"
    }
   },
   "outputs": [],
   "source": [
    "# spectrogram_transform = None\n",
    "# spectrogram_transform_first_epoch = None\n",
    "\n",
    "# spectrogram_transform = SpectrogramTransform(freq_mask_param=10, time_mask_param=10)\n",
    "# spectrogram_transform_first_epoch = None\n",
    "\n",
    "spectrogram_transform = SpectrogramTransform(freq_mask_param=10, time_mask_param=10)\n",
    "spectrogram_transform_first_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pressing-prague",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:00:46.088761Z",
     "start_time": "2021-03-24T07:59:56.657954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a88cd3dbb1490287578ffdef5451fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7893edcde6b64d5897fe8b7cfe908396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0667a4ea90374059b5f1f08348aec3af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216ae539ec37466abc5bc04764a6b573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e15c3102c44f129c2c65602e17060f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 of 100 took 3429.4976332187653s, train loss: 0.4655671967561739, val loss: 0.1750011304616928, train wer: 0.33901827462766493, val wer: 0.33320012792762793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ce0bf1acf3478a9c9d11c0336412d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-3627c43f5489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbeam_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfast_beam_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mspectrogram_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspectrogram_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mspectrogram_transform_first_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspectrogram_transform_first_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;32m/home/mnakhodnov/sirius-stt/src/optimization.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, loss_fn, num_epochs, train_dataloader, val_dataloaders, log_every_n_batch, model_dir, vocab, beam_kwargs, spectrogram_transform, spectrogram_transform_first_epoch, scheduler)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mgradient_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             gradient_norm_clipped = torch.sqrt(\n",
      "\u001b[0;32m/home/mnakhodnov/sirius-stt/src/optimization.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mgradient_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             gradient_norm_clipped = torch.sqrt(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "training(\n",
    "    model=model, optimizer=opt, loss_fn=loss_fn, num_epochs=num_epochs, \n",
    "#     train_dataloader=[common_voice_train_dataloader, 'common_voice/train'],\n",
    "#     train_dataloader=[ls_train_dataloader, 'libre_speech/train'],\n",
    "#     train_dataloader=[open_stt_train_dataloader, 'open_stt/train'],\n",
    "    train_dataloader=[combined_dataloader, 'combined/train'],\n",
    "    val_dataloaders={\n",
    "        'open_stt/test': ls_test_dataloader,\n",
    "        'libre_speech/dev': ls_dev_dataloader,\n",
    "        'libre_speech/test': ls_test_dataloader,\n",
    "        'common_voice/val': common_voice_val_dataloader,\n",
    "    }, log_every_n_batch=log_every_n_batch, model_dir=model_dir, vocab=vocab,\n",
    "    beam_kwargs=fast_beam_kwargs, \n",
    "    spectrogram_transform=spectrogram_transform, \n",
    "    spectrogram_transform_first_epoch=spectrogram_transform_first_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-moral",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
