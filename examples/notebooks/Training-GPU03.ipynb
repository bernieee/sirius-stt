{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "optical-integration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:01.021420Z",
     "start_time": "2021-03-24T08:00:01.006088Z"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becoming-password",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:01.273126Z",
     "start_time": "2021-03-24T08:00:01.256413Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polished-significance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:01.442362Z",
     "start_time": "2021-03-24T08:00:01.428479Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unnecessary-budapest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:02.985400Z",
     "start_time": "2021-03-24T08:00:01.687005Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import regex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import editdistance\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, BatchSampler, SequentialSampler, RandomSampler\n",
    "\n",
    "from vocabulary import Vocab\n",
    "\n",
    "from src.audio_utils import open_audio\n",
    "from src.audio_utils import make_transform, get_default_audio_transforms\n",
    "from src.audio_utils import AudioTransformsChain, AudioTransformsExclusive\n",
    "from src.audio_utils import SpectrogramTransform, compute_log_mel_spectrogram\n",
    "\n",
    "from src.datasets import AudioDataset\n",
    "from src.datasets import AudioDatasetSampler, collate_fn\n",
    "\n",
    "from src.datasets import manifest_train_test_split\n",
    "from src.datasets import convert_libri_manifest_to_common_voice\n",
    "from src.datasets import convert_open_stt_manifest_to_common_voice\n",
    "\n",
    "from src.deepspeech import Model\n",
    "\n",
    "from src.decoding import calc_wer, calc_wer_for_batch\n",
    "from src.decoding import decode, greedy_decoder, beam_search_decode, fast_beam_search_decode\n",
    "\n",
    "from src.optimization import get_prediction, get_model_results\n",
    "from src.optimization import get_prediction, get_model_results, validate, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arranged-corps",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:03.135110Z",
     "start_time": "2021-03-24T08:00:02.987493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: torch.float32, device: cuda:0, cuda_device_id 3\n"
     ]
    }
   ],
   "source": [
    "# Set proper device for computations,\n",
    "dtype, device, cuda_device_id = torch.float32, None, 3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{0}'.format(str(cuda_device_id) if cuda_device_id is not None else '')\n",
    "if cuda_device_id is not None and torch.cuda.is_available():\n",
    "    device = 'cuda:{0:d}'.format(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f'dtype: {dtype}, device: {device}, cuda_device_id {cuda_device_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-argument",
   "metadata": {},
   "source": [
    "# Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italian-bouquet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:04.004633Z",
     "start_time": "2021-03-24T08:00:03.984516Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_tokens(vocab):\n",
    "    ### write your code here ###\n",
    "    num_tokens = len(vocab.tokens2indices())\n",
    "    return num_tokens\n",
    "\n",
    "def get_blank_index(vocab):\n",
    "    ### write your code here ###\n",
    "    blank_index = vocab['<blank>']\n",
    "    return blank_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hairy-rochester",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:04.235777Z",
     "start_time": "2021-03-24T08:00:04.213712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `unk_token` '<unk>' wasn't found in the tokens. Adding the `unk_token` to the end of the Vocab.\n"
     ]
    }
   ],
   "source": [
    "alphabet = [\n",
    "    'а', 'б', 'в', 'г', 'д', 'е', 'ё', 'ж', 'з', 'и', 'й', 'к',\n",
    "    'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц',\n",
    "    'ч', 'ш', 'щ', 'ь', 'ы', 'ъ', 'э', 'ю', 'я', ' ', '<blank>'\n",
    "]\n",
    "\n",
    "vocab = Vocab(alphabet)\n",
    "\n",
    "num_tokens = get_num_tokens(vocab) \n",
    "blank_index = get_blank_index(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-subscription",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:16:50.445235Z",
     "start_time": "2021-03-23T14:16:50.427831Z"
    }
   },
   "source": [
    "# Choose Audio Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "honest-plastic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:05.331210Z",
     "start_time": "2021-03-24T08:00:05.311742Z"
    }
   },
   "outputs": [],
   "source": [
    "audio_transforms = get_default_audio_transforms()\n",
    "# audio_transforms = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surrounded-amazon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:05.781163Z",
     "start_time": "2021-03-24T08:00:05.762115Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-species",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-portsmouth",
   "metadata": {},
   "source": [
    "## Load Common Voice dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "introductory-corps",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:08.948349Z",
     "start_time": "2021-03-24T08:00:08.723996Z"
    }
   },
   "outputs": [],
   "source": [
    "common_voice_val_manifest_path = '/home/e.chuykova/data/val.txt'\n",
    "common_voice_test_manifest_path = '/home/e.chuykova/data/test.txt'\n",
    "common_voice_train_manifest_path = '/home/e.chuykova/data/train.txt'\n",
    "\n",
    "common_voice_val_dataset = AudioDataset(\n",
    "    common_voice_val_manifest_path, vocab, sample_rate=sample_rate,\n",
    ")\n",
    "common_voice_test_dataset = AudioDataset(\n",
    "    common_voice_test_manifest_path, vocab, sample_rate=sample_rate,\n",
    ")\n",
    "common_voice_train_dataset = AudioDataset(\n",
    "    common_voice_train_manifest_path, vocab, sample_rate=sample_rate,\n",
    "    audio_transforms=audio_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-advertising",
   "metadata": {},
   "source": [
    "## Load LibriSpeech dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "knowing-attention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:10.556188Z",
     "start_time": "2021-03-24T08:00:09.440784Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/dev/manifest.json'\n",
    "ls_test_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/test/manifest.json'\n",
    "ls_train_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/train/manifest.json'\n",
    "\n",
    "ls_dev_manifest_path = convert_libri_manifest_to_common_voice(ls_dev_manifest_path)\n",
    "ls_test_manifest_path = convert_libri_manifest_to_common_voice(ls_test_manifest_path)\n",
    "ls_train_manifest_path = convert_libri_manifest_to_common_voice(ls_train_manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "experienced-worry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:10.827707Z",
     "start_time": "2021-03-24T08:00:10.558267Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_dataset = AudioDataset(\n",
    "    ls_dev_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    ")\n",
    "ls_test_dataset = AudioDataset(\n",
    "    ls_test_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    ")\n",
    "ls_train_dataset = AudioDataset(\n",
    "    ls_train_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-group",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T11:00:14.720362Z",
     "start_time": "2021-03-22T11:00:14.703290Z"
    }
   },
   "source": [
    "## Load Open STT (radio_2) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "genetic-deputy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:10.850403Z",
     "start_time": "2021-03-24T08:00:10.829837Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.csv'\n",
    "\n",
    "# open_stt_manifest_path = convert_open_stt_manifest_to_common_voice(open_stt_manifest_path)\n",
    "# open_stt_test_manifest_path, open_stt_train_manifest_path = manifest_train_test_split(\n",
    "#     open_stt_manifest_path, ratio=0.005, seed=42\n",
    "# )\n",
    "open_stt_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.common_voice.csv'\n",
    "open_stt_test_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.common_voice_test.csv'\n",
    "open_stt_train_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.common_voice_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "enabling-therapy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:14.153590Z",
     "start_time": "2021-03-24T08:00:10.923210Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_test_dataset = AudioDataset(\n",
    "    open_stt_test_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    ")\n",
    "open_stt_train_dataset = AudioDataset(\n",
    "    open_stt_train_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-canvas",
   "metadata": {},
   "source": [
    "## Load Open STT (audiobook_2) dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "inappropriate-migration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:14.174676Z",
     "start_time": "2021-03-24T08:00:14.155709Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobook_2_manifest_path = '/data/mnakhodnov/voice_data/private_buriy_audiobooks_2/private_buriy_audiobooks_2.csv'\n",
    "# audiobook_2_manifest_path = convert_open_stt_manifest_to_common_voice(audiobook_2_manifest_path)\n",
    "# audiobook_2_test_manifest_path, audiobook_2_train_manifest_path = manifest_train_test_split(\n",
    "#     audiobook_2_manifest_path, ratio=0.005, seed=42\n",
    "# )\n",
    "audiobook_2_manifest_path = '/data/mnakhodnov/voice_data/private_buriy_audiobooks_2/private_buriy_audiobooks_2.common_voice.csv'\n",
    "audiobook_2_test_manifest_path = '/data/mnakhodnov/voice_data/private_buriy_audiobooks_2/private_buriy_audiobooks_2.common_voice_test.csv'\n",
    "audiobook_2_train_manifest_path = '/data/mnakhodnov/voice_data/private_buriy_audiobooks_2/private_buriy_audiobooks_2.common_voice_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "italian-flooring",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:18.926306Z",
     "start_time": "2021-03-24T08:00:14.176661Z"
    }
   },
   "outputs": [],
   "source": [
    "audiobook_2_test_dataset = AudioDataset(\n",
    "    audiobook_2_test_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    ")\n",
    "audiobook_2_train_dataset = AudioDataset(\n",
    "    audiobook_2_train_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-helmet",
   "metadata": {},
   "source": [
    "## Combine all datasets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "atmospheric-controversy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.550060Z",
     "start_time": "2021-03-24T08:00:18.928459Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined_dataset = AudioDataset(\n",
    "    dataset_path=[common_voice_train_manifest_path, ls_train_manifest_path, open_stt_train_manifest_path], \n",
    "    min_duration=[None, None, 2.0], max_duration=[None, 10.0, 10.0],\n",
    "    vocab=vocab, sample_rate=sample_rate,\n",
    "    audio_transforms=audio_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-decade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:15.279798Z",
     "start_time": "2021-03-23T14:19:15.262876Z"
    }
   },
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cutting-seminar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.571423Z",
     "start_time": "2021-03-24T08:00:22.551932Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-turning",
   "metadata": {},
   "source": [
    "## Common Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "advanced-billion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.599760Z",
     "start_time": "2021-03-24T08:00:22.573365Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "common_voice_val_dataloader = DataLoader(\n",
    "    common_voice_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "# YOUR CODE\n",
    "common_voice_test_dataloader = DataLoader(\n",
    "    common_voice_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "# YOUR CODE\n",
    "common_voice_train_dataloader = DataLoader(\n",
    "    common_voice_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(common_voice_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-brooks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:15.371150Z",
     "start_time": "2021-03-23T14:19:15.356303Z"
    }
   },
   "source": [
    "## Libri Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "current-greek",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.627649Z",
     "start_time": "2021-03-24T08:00:22.602087Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_dataloader = DataLoader(\n",
    "    ls_dev_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "ls_test_dataloader = DataLoader(\n",
    "    ls_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "ls_train_dataloader = DataLoader(\n",
    "    ls_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(ls_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-valentine",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:45.209964Z",
     "start_time": "2021-03-23T14:19:45.192687Z"
    }
   },
   "source": [
    "## OpenSTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "elementary-miracle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.721181Z",
     "start_time": "2021-03-24T08:00:22.629439Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_test_dataloader = DataLoader(\n",
    "    open_stt_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "open_stt_train_dataloader = DataLoader(\n",
    "    open_stt_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(open_stt_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-entry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:04:47.713051Z",
     "start_time": "2021-03-23T15:04:47.695886Z"
    }
   },
   "source": [
    "## Combined Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hourly-currency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.842909Z",
     "start_time": "2021-03-24T08:00:22.723037Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_dataloader = DataLoader(\n",
    "    combined_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(combined_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-gambling",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-briefs",
   "metadata": {},
   "source": [
    "## Choose LM for beam search decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ethical-version",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.864633Z",
     "start_time": "2021-03-24T08:00:22.845030Z"
    }
   },
   "outputs": [],
   "source": [
    "kenlm_bin_path = '/home/mnakhodnov/kenlm/build/bin'\n",
    "\n",
    "# This models are sorted wr to their size and speed \n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.1'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.2'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.3'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.4'\n",
    "kenlm_data_path = '/data/mnakhodnov/language_data/common_voice/train.txt'\n",
    "kenlm_arpa_path, kenlm_binary_path = kenlm_data_path + '.arpa', kenlm_data_path + '.binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "young-numbers",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.881467Z",
     "start_time": "2021-03-24T08:00:22.866217Z"
    }
   },
   "outputs": [],
   "source": [
    "fast_beam_kwargs = {\n",
    "    'beam_size': 10, 'cutoff_top_n': 5, 'cutoff_prob': 1.0, \n",
    "    'ext_scoring_func': kenlm_binary_path, 'alpha': 1.0, 'beta': 0.3, 'num_processes': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "recreational-mortality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.898124Z",
     "start_time": "2021-03-24T08:00:22.882981Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_from_ckpt(model, ckpt_path):\n",
    "    checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "funded-burton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:22.914567Z",
     "start_time": "2021-03-24T08:00:22.899640Z"
    }
   },
   "outputs": [],
   "source": [
    "num_tokens = len(vocab.tokens2indices()) - 1\n",
    "num_mel_bins = 64\n",
    "hidden_size= 512\n",
    "num_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "straight-updating",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:00:51.697196Z",
     "start_time": "2021-03-24T08:00:46.989285Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = 'models/8_recovered'\n",
    "log_every_n_batch = 10\n",
    "\n",
    "model = Model(\n",
    "    num_mel_bins=num_mel_bins,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    num_tokens=num_tokens\n",
    ")\n",
    "# load_from_ckpt(model, '/home/e.chuykova/data/ckpt.pt')\n",
    "load_from_ckpt(model, '/home/mnakhodnov/sirius-stt/models/6/epoch_6.pt')\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "engaging-accent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:01:16.240065Z",
     "start_time": "2021-03-24T08:01:16.219359Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "graduate-findings",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:01:16.462473Z",
     "start_time": "2021-03-24T08:01:16.439643Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 2e-4\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CTCLoss(blank=blank_index, reduction='mean')\n",
    "\n",
    "scheduler = ExponentialLR(opt, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "extreme-paradise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:01:20.381438Z",
     "start_time": "2021-03-24T08:01:20.361720Z"
    }
   },
   "outputs": [],
   "source": [
    "# ls_train_dataloader.sampler.epoch = 0\n",
    "# open_stt_train_dataloader.sampler.epoch = 0\n",
    "# common_voice_train_dataloader.sampler.epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "specified-munich",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T08:01:20.787820Z",
     "start_time": "2021-03-24T08:01:20.766641Z"
    }
   },
   "outputs": [],
   "source": [
    "# spectrogram_transform = None\n",
    "# spectrogram_transform_first_epoch = None\n",
    "\n",
    "# spectrogram_transform = SpectrogramTransform(freq_mask_param=10, time_mask_param=10)\n",
    "# spectrogram_transform_first_epoch = None\n",
    "\n",
    "spectrogram_transform = SpectrogramTransform(freq_mask_param=10, time_mask_param=10)\n",
    "spectrogram_transform_first_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pressing-prague",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:00:43.502481Z",
     "start_time": "2021-03-24T08:01:28.703169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bdd452d116407b8462c3e556a8a1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd85dcd0e77b46c88325ae17a318d02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b2d9685f0a4a69a8dd8ea270e6d41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa08920746a24a51a54be4687710f7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625e4a781f9a4448b53da975a3980097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 of 100 took 3442.3698761463165s, train loss: 0.4985746513998852, val loss: 0.18561499428749084, train wer: 0.3578486147663066, val wer: 0.33537783771783786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c409c3faf9754d0bb06a104e92c9362f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6032 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2cc2c60d27b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mspectrogram_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspectrogram_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mspectrogram_transform_first_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspectrogram_transform_first_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;32m/home/mnakhodnov/sirius-stt/src/optimization.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, optimizer, loss_fn, num_epochs, train_dataloader, val_dataloaders, log_every_n_batch, model_dir, vocab, beam_kwargs, spectrogram_transform, spectrogram_transform_first_epoch, scheduler)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mgradient_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             gradient_norm_clipped = torch.sqrt(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "training(\n",
    "    model=model, optimizer=opt, loss_fn=loss_fn, num_epochs=num_epochs, \n",
    "#     train_dataloader=[common_voice_train_dataloader, 'common_voice/train'],\n",
    "#     train_dataloader=[ls_train_dataloader, 'libre_speech/train'],\n",
    "#     train_dataloader=[open_stt_train_dataloader, 'open_stt/train'],\n",
    "    train_dataloader=[combined_dataloader, 'combined/train'],\n",
    "    val_dataloaders={\n",
    "        'open_stt/test': ls_test_dataloader,\n",
    "        'libre_speech/dev': ls_dev_dataloader,\n",
    "        'libre_speech/test': ls_test_dataloader,\n",
    "        'common_voice/val': common_voice_val_dataloader,\n",
    "    }, log_every_n_batch=log_every_n_batch, model_dir=model_dir, vocab=vocab,\n",
    "    beam_kwargs=fast_beam_kwargs, \n",
    "    spectrogram_transform=spectrogram_transform, \n",
    "    spectrogram_transform_first_epoch=spectrogram_transform_first_epoch,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-stand",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
