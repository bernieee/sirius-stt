{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protecting-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "freelance-detroit",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:15:19.273391Z",
     "start_time": "2021-03-23T14:15:19.261000Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "orange-honduras",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:15:24.184964Z",
     "start_time": "2021-03-23T14:15:24.176305Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "another-family",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:16:27.092531Z",
     "start_time": "2021-03-23T14:16:26.997379Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import regex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import editdistance\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, BatchSampler, SequentialSampler, RandomSampler\n",
    "\n",
    "from vocabulary import Vocab\n",
    "\n",
    "from src.audio_utils import open_audio\n",
    "from src.audio_utils import make_transform, get_default_audio_transforms\n",
    "from src.audio_utils import AudioTransformsChain, AudioTransformsExclusive\n",
    "from src.audio_utils import SpectrogramTransform, compute_log_mel_spectrogram\n",
    "\n",
    "from src.datasets import AudioDataset\n",
    "from src.datasets import AudioDatasetSampler, collate_fn\n",
    "\n",
    "from src.datasets import manifest_train_test_split\n",
    "from src.datasets import convert_libri_manifest_to_common_voice\n",
    "from src.datasets import convert_open_stt_manifest_to_common_voice\n",
    "\n",
    "from src.deepspeech import Model\n",
    "\n",
    "from src.decoding import calc_wer, calc_wer_for_batch\n",
    "from src.decoding import decode, greedy_decoder, beam_search_decode, fast_beam_search_decode\n",
    "\n",
    "from src.optimization import get_prediction, get_model_results\n",
    "from src.optimization import get_prediction, get_model_results, validate, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "derived-child",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:24:27.595727Z",
     "start_time": "2021-03-23T14:24:27.574034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: torch.float32, device: cuda:0, cuda_device_id 0\n"
     ]
    }
   ],
   "source": [
    "# Set proper device for computations,\n",
    "dtype, device, cuda_device_id = torch.float32, None, 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{0}'.format(str(cuda_device_id) if cuda_device_id is not None else '')\n",
    "if cuda_device_id is not None and torch.cuda.is_available():\n",
    "    device = 'cuda:{0:d}'.format(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f'dtype: {dtype}, device: {device}, cuda_device_id {cuda_device_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-democracy",
   "metadata": {},
   "source": [
    "# Create Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "strange-broadcast",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:24:36.358153Z",
     "start_time": "2021-03-23T14:24:36.338011Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_num_tokens(vocab):\n",
    "    ### write your code here ###\n",
    "    num_tokens = len(vocab.tokens2indices())\n",
    "    return num_tokens\n",
    "\n",
    "def get_blank_index(vocab):\n",
    "    ### write your code here ###\n",
    "    blank_index = vocab['<blank>']\n",
    "    return blank_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "civic-recorder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:24:36.492748Z",
     "start_time": "2021-03-23T14:24:36.475776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `unk_token` '<unk>' wasn't found in the tokens. Adding the `unk_token` to the end of the Vocab.\n"
     ]
    }
   ],
   "source": [
    "alphabet = [\n",
    "    'а', 'б', 'в', 'г', 'д', 'е', 'ё', 'ж', 'з', 'и', 'й', 'к',\n",
    "    'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц',\n",
    "    'ч', 'ш', 'щ', 'ь', 'ы', 'ъ', 'э', 'ю', 'я', ' ', '<blank>'\n",
    "]\n",
    "\n",
    "vocab = Vocab(alphabet)\n",
    "\n",
    "num_tokens = get_num_tokens(vocab) \n",
    "blank_index = get_blank_index(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-atmosphere",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:16:50.445235Z",
     "start_time": "2021-03-23T14:16:50.427831Z"
    }
   },
   "source": [
    "# Choose Audio Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "entertaining-lighting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:08.603983Z",
     "start_time": "2021-03-23T15:10:08.569126Z"
    }
   },
   "outputs": [],
   "source": [
    "# audio_transforms = get_default_audio_transforms()\n",
    "audio_transforms = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "productive-feedback",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:08.877154Z",
     "start_time": "2021-03-23T15:10:08.845411Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-detector",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-concentration",
   "metadata": {},
   "source": [
    "## Load Common Voice dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "quiet-cancellation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:10.080295Z",
     "start_time": "2021-03-23T15:10:09.845423Z"
    }
   },
   "outputs": [],
   "source": [
    "common_voice_val_manifest_path = '/home/e.chuykova/data/val.txt'\n",
    "common_voice_test_manifest_path = '/home/e.chuykova/data/test.txt'\n",
    "common_voice_train_manifest_path = '/home/e.chuykova/data/train.txt'\n",
    "\n",
    "common_voice_val_dataset = AudioDataset(\n",
    "    common_voice_val_manifest_path, vocab, sample_rate=sample_rate,\n",
    "#     evaluate_stats=True\n",
    ")\n",
    "common_voice_test_dataset = AudioDataset(\n",
    "    common_voice_test_manifest_path, vocab, sample_rate=sample_rate,\n",
    "#     evaluate_stats=True\n",
    ")\n",
    "common_voice_train_dataset = AudioDataset(\n",
    "    common_voice_train_manifest_path, vocab, sample_rate=sample_rate,\n",
    "    audio_transforms=audio_transforms,\n",
    "#     evaluate_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-mexican",
   "metadata": {},
   "source": [
    "## Load LibriSpeech dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "measured-premium",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:17:56.884849Z",
     "start_time": "2021-03-23T14:17:55.851492Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/dev/manifest.json'\n",
    "ls_test_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/test/manifest.json'\n",
    "ls_train_manifest_path = '/data/mnakhodnov/voice_data/libri_speech/train/manifest.json'\n",
    "\n",
    "ls_dev_manifest_path = convert_libri_manifest_to_common_voice(ls_dev_manifest_path)\n",
    "ls_test_manifest_path = convert_libri_manifest_to_common_voice(ls_test_manifest_path)\n",
    "ls_train_manifest_path = convert_libri_manifest_to_common_voice(ls_train_manifest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "further-clear",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:12.598727Z",
     "start_time": "2021-03-23T15:10:12.326033Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_dataset = AudioDataset(\n",
    "    ls_dev_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    "#     evaluate_stats=True\n",
    ")\n",
    "ls_test_dataset = AudioDataset(\n",
    "    ls_test_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    "#     evaluate_stats=True\n",
    ")\n",
    "ls_train_dataset = AudioDataset(\n",
    "    ls_train_manifest_path, vocab=vocab, sample_rate=sample_rate, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    "#     evaluate_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-bubble",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T11:00:14.720362Z",
     "start_time": "2021-03-22T11:00:14.703290Z"
    }
   },
   "source": [
    "## Load Open STT (radio_2) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hired-identification",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:15.260849Z",
     "start_time": "2021-03-23T14:17:59.837535Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_manifest_path = '/data/mnakhodnov/voice_data/radio_2/radio_2.csv'\n",
    "\n",
    "open_stt_manifest_path = convert_open_stt_manifest_to_common_voice(open_stt_manifest_path)\n",
    "open_stt_test_manifest_path, open_stt_train_manifest_path = manifest_train_test_split(open_stt_manifest_path, ratio=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "social-assessment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:17.483737Z",
     "start_time": "2021-03-23T15:10:14.143734Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_test_dataset = AudioDataset(\n",
    "    open_stt_test_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    "#     evaluate_stats=True\n",
    ")\n",
    "open_stt_train_dataset = AudioDataset(\n",
    "    open_stt_train_manifest_path, vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    "#     evaluate_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-anchor",
   "metadata": {},
   "source": [
    "## Combine all datasets for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "written-experiment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.122025Z",
     "start_time": "2021-03-23T15:10:17.485924Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_dataset = AudioDataset(\n",
    "    [common_voice_train_manifest_path, ls_train_manifest_path, open_stt_train_manifest_path], \n",
    "    vocab=vocab, sample_rate=sample_rate, min_duration=2.0, max_duration=10.0,\n",
    "    audio_transforms=audio_transforms,\n",
    "#     evaluate_stats=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-vessel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:15.279798Z",
     "start_time": "2021-03-23T14:19:15.262876Z"
    }
   },
   "source": [
    "# Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "formed-overhead",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.166680Z",
     "start_time": "2021-03-23T15:10:21.124430Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-vietnamese",
   "metadata": {},
   "source": [
    "## Common Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "temporal-fence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.219463Z",
     "start_time": "2021-03-23T15:10:21.168557Z"
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "common_voice_val_dataloader = DataLoader(\n",
    "    common_voice_val_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "# YOUR CODE\n",
    "common_voice_test_dataloader = DataLoader(\n",
    "    common_voice_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "# YOUR CODE\n",
    "common_voice_train_dataloader = DataLoader(\n",
    "    common_voice_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(common_voice_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-visibility",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:15.371150Z",
     "start_time": "2021-03-23T14:19:15.356303Z"
    }
   },
   "source": [
    "## Libri Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "scientific-nitrogen",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.270804Z",
     "start_time": "2021-03-23T15:10:21.221106Z"
    }
   },
   "outputs": [],
   "source": [
    "ls_dev_dataloader = DataLoader(\n",
    "    ls_dev_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "ls_test_dataloader = DataLoader(\n",
    "    ls_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "ls_train_dataloader = DataLoader(\n",
    "    ls_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(ls_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-roots",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T14:19:45.209964Z",
     "start_time": "2021-03-23T14:19:45.192687Z"
    }
   },
   "source": [
    "## OpenSTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "comprehensive-nutrition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.468923Z",
     "start_time": "2021-03-23T15:10:21.272437Z"
    }
   },
   "outputs": [],
   "source": [
    "open_stt_test_dataloader = DataLoader(\n",
    "    open_stt_test_dataset, batch_size=batch_size, shuffle=False, \n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")\n",
    "open_stt_train_dataloader = DataLoader(\n",
    "    open_stt_train_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(open_stt_train_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-kenya",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:04:47.713051Z",
     "start_time": "2021-03-23T15:04:47.695886Z"
    }
   },
   "source": [
    "## Combined Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "acoustic-bernard",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.589331Z",
     "start_time": "2021-03-23T15:10:21.470932Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_dataloader = DataLoader(\n",
    "    combined_dataset, batch_size=batch_size, \n",
    "    sampler=AudioDatasetSampler(combined_dataset, batch_size=batch_size),\n",
    "    num_workers=num_workers, pin_memory=True, collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-cartridge",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-australia",
   "metadata": {},
   "source": [
    "## Choose LM for beam search decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "resistant-genius",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.625819Z",
     "start_time": "2021-03-23T15:10:21.591704Z"
    }
   },
   "outputs": [],
   "source": [
    "kenlm_bin_path = '/home/mnakhodnov/kenlm/build/bin'\n",
    "\n",
    "# This models are sorted wr to their size and speed \n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.1'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.2'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.3'\n",
    "# kenlm_data_path = '/data/mnakhodnov/language_data/cc100/xaa.processed.4'\n",
    "kenlm_data_path = '/data/mnakhodnov/language_data/common_voice/train.txt'\n",
    "kenlm_arpa_path, kenlm_binary_path = kenlm_data_path + '.arpa', kenlm_data_path + '.binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "sound-partition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.658268Z",
     "start_time": "2021-03-23T15:10:21.627557Z"
    }
   },
   "outputs": [],
   "source": [
    "fast_beam_kwargs = {\n",
    "    'beam_size': 10, 'cutoff_top_n': 5, 'cutoff_prob': 1.0, \n",
    "    'ext_scoring_func': kenlm_binary_path, 'alpha': 1.0, 'beta': 0.3, 'num_processes': 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "hundred-colon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.690286Z",
     "start_time": "2021-03-23T15:10:21.659893Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_from_ckpt(model, ckpt_path):\n",
    "    checkpoint = torch.load(ckpt_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "desperate-owner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:21.722087Z",
     "start_time": "2021-03-23T15:10:21.691844Z"
    }
   },
   "outputs": [],
   "source": [
    "num_tokens = len(vocab.tokens2indices()) - 1\n",
    "num_mel_bins = 64\n",
    "hidden_size= 512\n",
    "num_layers = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "educational-prediction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:22.334432Z",
     "start_time": "2021-03-23T15:10:21.723660Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 7\n",
    "model_dir = 'models/6'\n",
    "log_every_n_batch = 10\n",
    "\n",
    "model = Model(\n",
    "    num_mel_bins=num_mel_bins,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    num_tokens=num_tokens\n",
    ")\n",
    "# load_from_ckpt(model, '/home/e.chuykova/data/ckpt.pt')\n",
    "load_from_ckpt(model, '/home/mnakhodnov/sirius-stt/models/2/epoch_5.pt')\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "going-geometry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:22.371654Z",
     "start_time": "2021-03-23T15:10:22.336190Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 2e-4\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.CTCLoss(blank=blank_index, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "great-failure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:23.275214Z",
     "start_time": "2021-03-23T15:10:23.241881Z"
    }
   },
   "outputs": [],
   "source": [
    "# ls_train_dataloader.sampler.epoch = 0\n",
    "# open_stt_train_dataloader.sampler.epoch = 0\n",
    "# common_voice_train_dataloader.sampler.epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "pacific-fashion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T15:10:23.483003Z",
     "start_time": "2021-03-23T15:10:23.452917Z"
    }
   },
   "outputs": [],
   "source": [
    "# spectrogram_transform = None\n",
    "# spectrogram_transform_first_epoch = None\n",
    "\n",
    "# spectrogram_transform = SpectrogramTransform(freq_mask_param=10, time_mask_param=10)\n",
    "# spectrogram_transform_first_epoch = None\n",
    "\n",
    "spectrogram_transform = SpectrogramTransform(freq_mask_param=10, time_mask_param=10)\n",
    "spectrogram_transform_first_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-street",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-23T15:10:25.192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28219000377f4ff2b7433bd3d55ccb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6013 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "training(\n",
    "    model=model, optimizer=opt, loss_fn=loss_fn, num_epochs=num_epochs, \n",
    "#     train_dataloader=[common_voice_train_dataloader, 'common_voice/train'],\n",
    "#     train_dataloader=[ls_train_dataloader, 'libre_speech/train'],\n",
    "#     train_dataloader=[open_stt_train_dataloader, 'open_stt/train'],\n",
    "    train_dataloader=[combined_dataloader, 'combined/train'],\n",
    "    val_dataloaders={\n",
    "        'open_stt/test': ls_test_dataloader,\n",
    "        'libre_speech/dev': ls_dev_dataloader,\n",
    "        'libre_speech/test': ls_test_dataloader,\n",
    "        'common_voice/val': common_voice_val_dataloader,\n",
    "    }, log_every_n_batch=log_every_n_batch, model_dir=model_dir, vocab=vocab,\n",
    "    beam_kwargs=fast_beam_kwargs, \n",
    "    spectrogram_transform=None, \n",
    "    spectrogram_transform_first_epoch=spectrogram_transform_first_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-civilization",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
